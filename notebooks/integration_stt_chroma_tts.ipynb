{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "605b8a33",
   "metadata": {},
   "source": [
    "# Integration e2e tests for Whisper - ChromaDB - Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904fb04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU sounddevice scipy pydub ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3e945e",
   "metadata": {},
   "source": [
    "## Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a579ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write\n",
    "from pydub import AudioSegment\n",
    "from IPython.display import display, Audio\n",
    "from uuid import uuid4\n",
    "import ipywidgets as widgets\n",
    "import threading\n",
    "import queue\n",
    "\n",
    "samplerate = 44100\n",
    "channels = 1\n",
    "q = queue.Queue()\n",
    "recording = []\n",
    "stream = None\n",
    "\n",
    "TMP_PATH = \"../tmp/\"\n",
    "UID = str(uuid4())\n",
    "\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    if status:\n",
    "        print(status)\n",
    "    q.put(indata.copy())\n",
    "\n",
    "def start_recording(b):\n",
    "    global stream, recording\n",
    "    recording = []\n",
    "\n",
    "    stream = sd.InputStream(samplerate=samplerate, channels=channels, callback=audio_callback)\n",
    "    stream.start()\n",
    "\n",
    "    def collect():\n",
    "        while stream.active:\n",
    "            chunk = q.get()\n",
    "            recording.append(chunk)\n",
    "\n",
    "    threading.Thread(target=collect, daemon=True).start()\n",
    "\n",
    "def stop_recording(b):\n",
    "    global stream\n",
    "\n",
    "    stream.stop()\n",
    "    stream.close()\n",
    "\n",
    "    audio_data = np.concatenate(recording, axis=0)\n",
    "\n",
    "    # Save .wav\n",
    "    wav_path = TMP_PATH + UID + \".wav\"\n",
    "    write(wav_path, samplerate, audio_data)\n",
    "\n",
    "    display(Audio(filename=wav_path))\n",
    "\n",
    "# Widgets\n",
    "start_button = widgets.Button(description=\"Record\")\n",
    "stop_button = widgets.Button(description=\"Stop\")\n",
    "\n",
    "start_button.on_click(start_recording)\n",
    "stop_button.on_click(stop_recording)\n",
    "\n",
    "display(widgets.HBox([start_button, stop_button]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2389f18a",
   "metadata": {},
   "source": [
    "## STT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d752e380",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-openai langchain-community pydub librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8f0e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85b7dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.parsers.audio import OpenAIWhisperParser\n",
    "\n",
    "parser = OpenAIWhisperParser(\n",
    "  api_key=OPENAI_API_KEY,\n",
    "  chunk_duration_threshold=0.7, # means the parser will disregard audio chunks shorter than 0.7 seconds\n",
    "  language=\"fr\",  # Specify the language of the audio\n",
    "  response_format=\"text\",\n",
    "  temperature=0.0, # deterministic\n",
    "  model=\"whisper-1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1721cf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.generic import GenericLoader\n",
    "\n",
    "# Define the path to the audio file\n",
    "# audio_path = \"../data/audio/test_whisper_clovis.m4a\"\n",
    "\n",
    "# Create a GenericLoader instance with the audio file and the parser\n",
    "# https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.generic.GenericLoader.html\n",
    "loader = GenericLoader.from_filesystem(TMP_PATH + f\"{UID}.wav\", parser=parser)\n",
    "\n",
    "# Load the documents using the loader\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5623355",
   "metadata": {},
   "source": [
    "## Save to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f2ad89",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU chromadb python-dotenv langchain-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a2c6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6f1cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate chroma client\n",
    "\n",
    "import os\n",
    "import chromadb\n",
    "from chromadb.api import ClientAPI\n",
    "\n",
    "def get_chroma_client() -> ClientAPI:\n",
    "  chroma_client = chromadb.CloudClient(\n",
    "    api_key=os.getenv(\"CHROMA_API_KEY\"),\n",
    "    tenant=os.getenv(\"CHROMA_TENANT\"),\n",
    "    database=os.getenv(\"CHROMA_DATABASE\")\n",
    "  )\n",
    "\n",
    "  return chroma_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a5a68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate langchain vector store\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "def get_chroma_collection(collection_name: str):\n",
    "  collection = Chroma(\n",
    "      client=get_chroma_client(),\n",
    "      embedding_function=OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    "      collection_name=collection_name,\n",
    "  )\n",
    "\n",
    "  return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c5d334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add documents\n",
    "\n",
    "from uuid import uuid4\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "documents = []\n",
    "\n",
    "for doc in docs:\n",
    "    document = Document(page_content=doc.page_content, metadata={\"tag\": \"test\"})\n",
    "    documents.append(document)\n",
    "\n",
    "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "collection = get_chroma_collection(\"test_collection\")\n",
    "collection.add_documents(documents=documents, ids=uuids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee708db",
   "metadata": {},
   "source": [
    "## Retrieve from DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f513b411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Widgets\n",
    "start_button = widgets.Button(description=\"Record\")\n",
    "stop_button = widgets.Button(description=\"Stop\")\n",
    "\n",
    "start_button.on_click(start_recording)\n",
    "stop_button.on_click(stop_recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01d77be",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = GenericLoader.from_filesystem(TMP_PATH + f\"{UID}.wav\", parser=parser)\n",
    "docs = loader.load()\n",
    "\n",
    "# Query by retriever\n",
    "\n",
    "retriever = collection.as_retriever(\n",
    "    search_type=\"mmr\", search_kwargs={\"k\": 1, \"fetch_k\": 5}\n",
    ")\n",
    "\n",
    "query_res = retriever.invoke(docs[0].page_content, filter=None, score_threshold=0)\n",
    "query_res_parsed = query_res[0].page_content\n",
    "\n",
    "print(query_res_parsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712f276b",
   "metadata": {},
   "source": [
    "# TTS Google\n",
    "\n",
    "Link to [Google TTS](https://python.langchain.com/docs/integrations/tools/google_cloud_texttospeech/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e5042b",
   "metadata": {},
   "source": [
    "## Setup google account\n",
    "\n",
    "Link to [Google Cloud Console Tutorial](https://cloud.google.com/text-to-speech?hl=fr)\n",
    "\n",
    "https://cloud.google.com/text-to-speech/docs/apis?hl=fr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68ad9de",
   "metadata": {},
   "source": [
    "## Install the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec40a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU google-cloud-texttospeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a84622d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"../secrets/google_tts.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76017463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import texttospeech\n",
    "\n",
    "# Crée un client\n",
    "client = texttospeech.TextToSpeechClient()\n",
    "\n",
    "# Définir le texte et la configuration\n",
    "synthesis_input = texttospeech.SynthesisInput(text=query_res_parsed)\n",
    "\n",
    "voice = texttospeech.VoiceSelectionParams(\n",
    "    language_code=\"fr-FR\",\n",
    "    name=\"fr-FR-Chirp3-HD-Charon\"\n",
    ")\n",
    "\n",
    "audio_config = texttospeech.AudioConfig(\n",
    "    audio_encoding=texttospeech.AudioEncoding.MP3\n",
    ")\n",
    "\n",
    "# Appel de l'API\n",
    "response = client.synthesize_speech(\n",
    "    input=synthesis_input,\n",
    "    voice=voice,\n",
    "    audio_config=audio_config\n",
    ")\n",
    "\n",
    "# Sauvegarde du résultat\n",
    "uid_2 = str(uuid4())\n",
    "with open(f\"../data/audio/{uid_2}.mp3\", \"wb\") as out:\n",
    "    out.write(response.audio_content)\n",
    "\n",
    "display(Audio(filename=f\"../data/audio/{uid_2}.mp3\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
